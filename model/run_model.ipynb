{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-03-17 17:51:14,115 INFO] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from stog.utils.params import Params\n",
    "from stog.data.dataset_builder import dataset_from_params, iterator_from_params\n",
    "from stog.data.vocabulary import Vocabulary\n",
    "from stog.training.trainer import Trainer\n",
    "from stog.data.dataset import Batch\n",
    "from model.text_to_amr import TextToAMR\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense, Flatten, LSTM, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adylanrff/Documents/Kuliah/TA/amr_parser/stog/utils/params.py:104: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  dict_merge.dict_merge(params_dict, yaml.load(f))\n"
     ]
    }
   ],
   "source": [
    "params = Params.from_file(\"../model/model_params.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-03-17 17:51:14,215 INFO] Building train datasets ...\n",
      "[2020-03-17 17:51:14,216 ERROR] Model name 'data/bert-base-cased/bert-base-cased-vocab.txt' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese). We assumed 'data/bert-base-cased/bert-base-cased-vocab.txt' was a path or url but couldn't find any file associated to this path or url.\n",
      "0it [00:00, ?it/s][2020-03-17 17:51:14,218 INFO] Reading instances from lines in file at: ../data/raw/amr.txt.features\n",
      "[2020-03-17 17:51:14,274 INFO] POS tag coverage: 0.3087 (184/596)\n",
      "40it [00:00, 701.85it/s]\n",
      "[2020-03-17 17:51:14,275 INFO] Building dev datasets ...\n",
      "[2020-03-17 17:51:14,276 ERROR] Model name 'data/bert-base-cased/bert-base-cased-vocab.txt' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese). We assumed 'data/bert-base-cased/bert-base-cased-vocab.txt' was a path or url but couldn't find any file associated to this path or url.\n",
      "0it [00:00, ?it/s][2020-03-17 17:51:14,279 INFO] Reading instances from lines in file at: ../data/raw/amr.txt.features\n",
      "[2020-03-17 17:51:14,334 INFO] POS tag coverage: 0.3087 (184/596)\n",
      "40it [00:00, 713.52it/s]\n",
      "[2020-03-17 17:51:14,335 INFO] Building test datasets ...\n",
      "[2020-03-17 17:51:14,336 ERROR] Model name 'data/bert-base-cased/bert-base-cased-vocab.txt' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese). We assumed 'data/bert-base-cased/bert-base-cased-vocab.txt' was a path or url but couldn't find any file associated to this path or url.\n",
      "0it [00:00, ?it/s][2020-03-17 17:51:14,339 INFO] Reading instances from lines in file at: ../data/raw/amr.txt.features\n",
      "[2020-03-17 17:51:14,394 INFO] POS tag coverage: 0.3087 (184/596)\n",
      "40it [00:00, 712.05it/s]\n"
     ]
    }
   ],
   "source": [
    "data_params = params['data']\n",
    "dataset = dataset_from_params(data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "dev_data = dataset.get('dev')\n",
    "test_data = dataset.get('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-03-17 17:51:14,414 INFO] Fitting token dictionary from dataset.\n",
      "100%|██████████| 40/40 [00:00<00:00, 2693.79it/s]\n",
      "[2020-03-17 17:51:14,436 WARNING] vocabulary serialization directory ../data/processed/serialization is not empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_tokens\n",
      "   encoder_tokens\n",
      "   encoder_characters\n",
      "src_must_copy_tags\n",
      "tgt_tokens\n",
      "   decoder_tokens\n",
      "   decoder_characters\n",
      "src_pos_tags\n",
      "tgt_pos_tags\n",
      "tgt_copy_indices\n",
      "tgt_copy_mask\n",
      "tgt_copy_map\n",
      "src_copy_indices\n",
      "src_copy_map\n",
      "head_tags\n",
      "head_indices\n"
     ]
    }
   ],
   "source": [
    "vocab_params = params.get('vocab', {})\n",
    "vocab = Vocabulary.from_instances(instances=train_data, **vocab_params)\n",
    "vocab.save_to_files(\"../data/processed/serialization\")\n",
    "\n",
    "dataset = Batch(train_data)\n",
    "dataset.index_instances(vocab)\n",
    "dataset.index_instances(vocab)\n",
    "\n",
    "# print(dataset.as_tensor_dict()['src_tokens']['encoder_tokens'][1].numpy())\n",
    "# print(dataset.as_tensor_dict()['tgt_tokens']['decoder_tokens'][1].numpy())\n",
    "# print(dataset.get_padding_lengths())\n",
    "# print(dataset.as_tensor_dict())\n",
    "\n",
    "for key in dataset.as_tensor_dict():\n",
    "    print(key)\n",
    "    content = dataset.as_tensor_dict()[key]\n",
    "    if isinstance(content, dict):\n",
    "        for inner_key in content:\n",
    "            print(\"  \", inner_key)\n",
    "\n",
    "train_iterator, dev_iterater, test_iterater = iterator_from_params(vocab, data_params['iterator'])\n",
    "\n",
    "train_dataset = Batch(train_data)\n",
    "train_dataset.index_instances(vocab)\n",
    "\n",
    "test_dataset = Batch(test_data)\n",
    "test_dataset.index_instances(vocab)\n",
    "\n",
    "train_dataset = train_dataset.as_tensor_dict()\n",
    "test_dataset = test_dataset.as_tensor_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary with namespaces:\n",
      " \tNon Padded Namespaces: {'must_copy_tags', 'coref_tags'}\n",
      " \tNamespace: encoder_token_ids, Size: 334 \n",
      " \tNamespace: encoder_token_characters, Size: 39 \n",
      " \tNamespace: decoder_token_ids, Size: 283 \n",
      " \tNamespace: decoder_token_characters, Size: 65 \n",
      " \tNamespace: pos_tags, Size: 16 \n",
      " \tNamespace: head_tags, Size: 35 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER_INPUT\n",
      "bert_token: None\n",
      "token_subword_index: None\n",
      "token: (40, 25)\n",
      "pos_tag: (40, 25)\n",
      "must_copy_tag: (40, 25)\n",
      "char: (40, 25, 14)\n",
      "mask: torch.Size([40, 25])\n",
      "\n",
      "DECODER_INPUT\n",
      "token: (40, 28)\n",
      "pos_tag: (40, 28)\n",
      "char: (40, 28, 17)\n",
      "coref: (40, 28)\n",
      "\n",
      "GENERATOR_INPUT\n",
      "vocab_targets: (40, 28)\n",
      "coref_targets: (40, 28)\n",
      "coref_attention_maps: (40, 28, 29)\n",
      "copy_targets: (40, 28)\n",
      "copy_attention_maps: (40, 25, 27)\n",
      "\n",
      "PARSER_INPUT\n",
      "edge_heads: (40, 28)\n",
      "edge_labels: (40, 28)\n",
      "corefs: (40, 28)\n",
      "mask: (40, 28)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_to_amr = TextToAMR(vocab)\n",
    "encoder_input, decoder_input, generator_input, parser_input = text_to_amr.prepare_input(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'sentinel:0' shape=(1, 1, 400) dtype=float32, numpy=\n",
      "array([[[ 1.00144267e-01, -3.47071812e-02,  7.04840571e-02,\n",
      "          1.01418182e-01, -2.71602422e-02,  8.90813172e-02,\n",
      "         -2.83640027e-02,  3.53339911e-02, -6.20715357e-02,\n",
      "         -1.18013494e-01, -5.09940013e-02, -1.06132381e-01,\n",
      "          2.70313919e-02,  1.17722765e-01, -7.33218342e-02,\n",
      "          1.49951577e-02,  3.67445350e-02, -7.84051418e-02,\n",
      "          9.69815552e-02, -9.97421071e-02, -9.35115665e-03,\n",
      "         -3.79691720e-02, -3.42761725e-03, -1.11319363e-01,\n",
      "         -6.67885989e-02,  8.72317553e-02,  1.01736695e-01,\n",
      "         -5.64232469e-04,  4.86955792e-02,  9.89654660e-03,\n",
      "         -5.86540401e-02,  3.47532928e-02,  4.93946671e-02,\n",
      "          7.97337294e-02, -2.09230706e-02, -7.22014830e-02,\n",
      "          1.10242367e-01, -1.05883934e-01,  8.73080194e-02,\n",
      "          6.08511269e-03, -6.76861107e-02, -5.67110330e-02,\n",
      "          6.98467195e-02, -4.12532166e-02, -9.10688937e-02,\n",
      "         -1.09147362e-01,  7.79286027e-04, -7.35917762e-02,\n",
      "         -5.46199605e-02, -6.20911941e-02, -8.52126032e-02,\n",
      "          5.08288145e-02,  6.72074556e-02, -1.00820959e-01,\n",
      "          1.71189755e-02, -8.10690150e-02,  1.40323192e-02,\n",
      "          1.14106044e-01, -1.20418511e-01, -4.09980938e-02,\n",
      "          2.89095342e-02, -3.63238156e-02, -3.25406343e-03,\n",
      "          9.43010747e-02,  7.95186162e-02,  4.26537544e-02,\n",
      "         -8.65832418e-02, -8.97315592e-02,  6.00046366e-02,\n",
      "          9.45031494e-02, -7.58326352e-02, -4.32500914e-02,\n",
      "         -9.77664664e-02,  9.67143774e-02, -3.95406336e-02,\n",
      "          1.17414728e-01,  6.14853203e-02, -9.96383429e-02,\n",
      "          2.89027095e-02,  3.27565372e-02, -2.34664753e-02,\n",
      "         -1.14446588e-01,  6.07624352e-02,  3.22929472e-02,\n",
      "         -1.26286969e-02,  6.59752190e-02, -1.14912860e-01,\n",
      "          5.41068017e-02,  1.93376690e-02,  4.60572839e-02,\n",
      "          2.45811492e-02,  2.62450427e-03,  3.62606198e-02,\n",
      "          8.68516862e-02,  9.25581306e-02,  1.10662803e-01,\n",
      "          4.94465381e-02, -6.38052672e-02, -2.21147314e-02,\n",
      "         -5.90919331e-02, -7.75723979e-02,  8.06005299e-02,\n",
      "          1.16233379e-02,  6.86725229e-02, -2.97621116e-02,\n",
      "          7.50400424e-02,  7.75836557e-02, -7.70293921e-02,\n",
      "         -1.84809864e-02, -6.48779124e-02,  1.09108627e-01,\n",
      "          4.41287011e-02,  8.71211290e-03, -1.96292549e-02,\n",
      "         -8.35622251e-02, -1.18260421e-01, -1.10771805e-02,\n",
      "          4.17980552e-03,  1.03244960e-01,  1.13422155e-01,\n",
      "         -3.51115316e-02, -8.48927051e-02, -1.07418418e-01,\n",
      "         -7.66629279e-02, -1.78057849e-02,  5.14836013e-02,\n",
      "         -5.80810905e-02,  6.85898960e-02,  5.39383292e-03,\n",
      "         -7.66442865e-02, -4.70271483e-02, -6.81331381e-02,\n",
      "          2.10504383e-02,  1.17615178e-01,  8.12150538e-04,\n",
      "         -1.02570206e-01, -7.04441369e-02, -5.73115125e-02,\n",
      "          3.93574834e-02,  5.92768192e-03,  1.00270092e-01,\n",
      "         -9.31155756e-02,  3.18160653e-02,  3.92129570e-02,\n",
      "         -1.33146569e-02,  1.45712346e-02,  4.75957841e-02,\n",
      "          4.71802056e-03,  7.49418586e-02,  4.38001454e-02,\n",
      "         -4.42936867e-02, -8.78928602e-03, -5.88669926e-02,\n",
      "         -1.06279686e-01, -2.70136073e-02,  5.25892675e-02,\n",
      "          5.24890870e-02, -1.03181377e-02, -2.27076337e-02,\n",
      "         -4.77089360e-02, -1.04997382e-02, -3.77537757e-02,\n",
      "         -7.10918307e-02, -1.27931237e-02,  8.72018635e-02,\n",
      "         -2.42425203e-02,  8.77254754e-02, -1.18681043e-02,\n",
      "         -4.44272608e-02, -8.61333907e-02,  7.42582977e-03,\n",
      "         -9.23830941e-02, -4.27704602e-02,  4.83538061e-02,\n",
      "         -3.59845534e-02,  2.29067653e-02,  6.73300028e-02,\n",
      "          1.87477767e-02, -1.07095659e-01, -2.95774192e-02,\n",
      "          5.02581745e-02, -5.04855886e-02,  9.86652970e-02,\n",
      "          1.04532257e-01,  1.21991783e-02, -1.22139610e-01,\n",
      "         -2.02677622e-02,  9.98950452e-02,  8.66010040e-02,\n",
      "         -6.62764609e-02, -1.00441426e-02,  7.16131628e-02,\n",
      "         -3.01230475e-02,  1.04946196e-01, -1.20244198e-01,\n",
      "          1.18478686e-02,  1.49245858e-02, -5.48741519e-02,\n",
      "         -1.10308483e-01,  5.95798790e-02,  9.78460759e-02,\n",
      "         -6.71085566e-02, -1.95057467e-02,  9.46202427e-02,\n",
      "         -9.73700136e-02, -8.58797282e-02,  1.10034838e-01,\n",
      "          2.45370716e-02,  3.14263105e-02, -5.82518131e-02,\n",
      "          2.25012451e-02,  8.39319676e-02, -3.49763334e-02,\n",
      "          7.50987530e-02, -5.09346873e-02,  3.29590738e-02,\n",
      "         -6.28664196e-02,  1.03116676e-01, -1.35567188e-02,\n",
      "         -8.61433148e-03, -9.83823761e-02,  3.20758224e-02,\n",
      "         -8.40093344e-02,  5.84447831e-02,  7.96502233e-02,\n",
      "         -1.07146405e-01,  1.21735632e-01,  1.03659526e-01,\n",
      "         -8.12854096e-02,  1.03624389e-01,  8.33477229e-02,\n",
      "          1.01680532e-01,  1.01505056e-01,  9.77714360e-03,\n",
      "          4.11891490e-02,  4.26351726e-02, -5.04287779e-02,\n",
      "         -1.21695362e-01, -4.75929528e-02,  2.28083134e-02,\n",
      "          8.79737437e-02,  2.47315764e-02,  1.83284283e-02,\n",
      "          5.03506511e-02, -4.98758629e-02,  1.10863850e-01,\n",
      "          2.58821696e-02,  8.32763612e-02, -7.21670687e-02,\n",
      "          6.06463850e-03, -6.33962750e-02, -1.13949612e-01,\n",
      "          1.14774913e-01,  3.23779285e-02, -1.14618830e-01,\n",
      "          1.10564187e-01,  8.69190842e-02, -7.18567967e-02,\n",
      "         -1.96483582e-02, -1.15131006e-01, -1.49333328e-02,\n",
      "          3.72165442e-02, -1.11075170e-01,  6.76000267e-02,\n",
      "          9.43563432e-02,  7.51474351e-02,  1.16150633e-01,\n",
      "          6.01624995e-02, -8.61719400e-02, -3.48972380e-02,\n",
      "          4.46033180e-02, -1.37687922e-02, -6.18254393e-03,\n",
      "         -4.15064394e-03, -5.16026542e-02, -3.00875232e-02,\n",
      "          5.15474677e-02, -5.15726134e-02,  8.57840627e-02,\n",
      "         -2.63078436e-02,  3.60529125e-02, -2.04367936e-03,\n",
      "          1.20281234e-01, -1.10083573e-01, -3.95759791e-02,\n",
      "         -1.41634941e-02,  3.91727090e-02, -7.55359232e-02,\n",
      "          9.18356329e-02, -1.16271526e-02,  2.67259777e-03,\n",
      "         -8.45020860e-02, -4.88918200e-02,  3.34061533e-02,\n",
      "         -6.64522797e-02, -1.12447292e-02, -6.78985417e-02,\n",
      "         -4.42860201e-02, -4.71112281e-02,  8.36147815e-02,\n",
      "          1.11445785e-02, -1.13337085e-01,  8.83495659e-02,\n",
      "         -8.74568373e-02, -9.30065885e-02, -5.24727255e-02,\n",
      "         -1.12285294e-01, -7.11083114e-02, -4.76743281e-03,\n",
      "          4.57299799e-02,  4.18619215e-02,  3.94483358e-02,\n",
      "         -4.48732898e-02,  1.80199891e-02,  9.95456874e-02,\n",
      "         -8.32657516e-03, -2.66332179e-03,  1.06101289e-01,\n",
      "         -7.96458274e-02,  1.10308245e-01, -9.57448930e-02,\n",
      "          4.86844033e-02,  1.10029384e-01, -3.61994877e-02,\n",
      "         -1.08888678e-01, -9.26551968e-02,  1.22550726e-02,\n",
      "          4.72928882e-02,  1.09424159e-01, -1.11324459e-01,\n",
      "          6.51407838e-02,  5.37407100e-02,  2.65382081e-02,\n",
      "         -4.92987037e-03, -5.69099560e-02, -7.83950090e-05,\n",
      "         -2.84660161e-02,  8.80983919e-02,  4.49160188e-02,\n",
      "         -5.09476662e-03,  7.55865127e-02,  7.92697221e-02,\n",
      "          7.44050443e-02, -1.13284558e-01, -7.71564394e-02,\n",
      "         -3.87790799e-02, -9.81939435e-02, -5.52871823e-03,\n",
      "         -3.61757800e-02,  1.13938734e-01,  5.89156151e-02,\n",
      "          6.40386343e-03,  7.75499344e-02, -8.44300240e-02,\n",
      "          1.07598603e-02,  1.01564169e-01, -5.21568209e-02,\n",
      "          8.41811299e-04,  5.04351109e-02, -8.87280554e-02,\n",
      "         -7.04240948e-02,  2.29918063e-02,  1.44460946e-02,\n",
      "          1.15436465e-01, -2.87423283e-03,  5.25305569e-02,\n",
      "         -2.11635306e-02, -3.22255790e-02,  9.22162831e-02,\n",
      "          4.79162931e-02, -3.78744528e-02,  1.01784006e-01,\n",
      "         -2.90604308e-02, -1.20414570e-02,  9.42383260e-02,\n",
      "          8.95792991e-02,  5.93023449e-02, -9.82329696e-02,\n",
      "          1.09009087e-01,  1.16112798e-01,  4.44740355e-02,\n",
      "          9.69698876e-02,  2.58149803e-02,  1.41469836e-02,\n",
      "         -8.99185538e-02,  3.92144322e-02,  1.16005242e-02,\n",
      "         -5.86805195e-02, -6.41031116e-02, -2.23880261e-02,\n",
      "          1.01193443e-01, -1.07559510e-01,  5.99525869e-02,\n",
      "          9.52515304e-02,  6.68659359e-02,  3.49606425e-02,\n",
      "         -9.41438898e-02,  1.14256442e-01, -7.34528452e-02,\n",
      "          7.85808861e-02]]], dtype=float32)>, <tf.Variable 'W_d:0' shape=(1, 256) dtype=float32, numpy=\n",
      "array([[-0.03368237, -0.14010954, -0.10551451,  0.09286536,  0.08490202,\n",
      "        -0.1411612 ,  0.01248147, -0.10274382, -0.04305417,  0.12662588,\n",
      "        -0.0067061 , -0.00745089, -0.05609504, -0.06574465, -0.00856052,\n",
      "         0.01350272, -0.03986126,  0.04573312,  0.07935958,  0.11235224,\n",
      "        -0.09878499, -0.07563255, -0.07719772, -0.08515549, -0.04158538,\n",
      "         0.06453131,  0.11053143,  0.05072542,  0.12571584,  0.11940895,\n",
      "         0.00065252,  0.13830678,  0.03967063, -0.14966363,  0.04976118,\n",
      "         0.06568775, -0.01361139, -0.02966492,  0.05550098,  0.08583365,\n",
      "         0.1322091 , -0.07465719,  0.0044743 , -0.00375727,  0.14968286,\n",
      "        -0.09238045,  0.08563289, -0.10190642, -0.02242026, -0.12790515,\n",
      "        -0.12960027,  0.12010227, -0.06410545,  0.06739591, -0.01452926,\n",
      "         0.0191507 , -0.00222251,  0.15273137,  0.03646952, -0.11147316,\n",
      "         0.14833276,  0.09320378, -0.0682144 , -0.06287068,  0.10137089,\n",
      "        -0.13628247, -0.13986394, -0.12795636, -0.0891823 , -0.03641182,\n",
      "         0.09080212,  0.01190002, -0.12540013, -0.03361136, -0.02263558,\n",
      "        -0.03111549,  0.01861475,  0.05408973,  0.00568458, -0.10145988,\n",
      "        -0.09565248,  0.09187987,  0.08825299,  0.01144123, -0.06108537,\n",
      "         0.08679219, -0.01160043, -0.14256191, -0.08199883,  0.06937234,\n",
      "        -0.00313972,  0.02710205,  0.01811852,  0.09809659, -0.08972754,\n",
      "         0.13945748, -0.1369554 ,  0.02169757,  0.1470655 , -0.09562119,\n",
      "        -0.03775303, -0.00728357,  0.09773968,  0.12345956,  0.02388431,\n",
      "        -0.03451525, -0.09384891, -0.11924095,  0.09664646, -0.071197  ,\n",
      "        -0.06313115,  0.03752312, -0.07162534,  0.09104413,  0.03414673,\n",
      "         0.07306907,  0.14018337,  0.03972039, -0.03437998,  0.11906193,\n",
      "         0.07033695,  0.0534759 ,  0.12669657,  0.02936384,  0.02472545,\n",
      "        -0.1250668 ,  0.02613719,  0.07593888, -0.12925036,  0.06290215,\n",
      "        -0.10353983, -0.13307637, -0.0495508 , -0.02737115,  0.06808683,\n",
      "         0.03345378, -0.11207132,  0.04033524, -0.11162467,  0.00719585,\n",
      "         0.09285888,  0.09348607, -0.1421561 , -0.02341571,  0.08585919,\n",
      "         0.12064652,  0.06375377, -0.00415544,  0.11972751, -0.09408957,\n",
      "         0.13747327, -0.05194842, -0.10175375,  0.03751257, -0.14162019,\n",
      "        -0.09258059, -0.09282966,  0.12931506, -0.05705054,  0.01876597,\n",
      "        -0.09694164,  0.11373891,  0.15208389, -0.10909608,  0.02941673,\n",
      "        -0.00305812,  0.00175439,  0.04738581,  0.02280018,  0.12022556,\n",
      "         0.03099273,  0.04633781,  0.01947415, -0.14519694,  0.05041103,\n",
      "         0.07362978, -0.06456427,  0.125248  ,  0.13899727,  0.07455625,\n",
      "        -0.07152363,  0.13713829,  0.12751864,  0.01549959, -0.0323907 ,\n",
      "         0.09403856,  0.14469962, -0.01760009, -0.05433755, -0.14476201,\n",
      "         0.09583379,  0.08723177, -0.10415094, -0.13975792, -0.03541829,\n",
      "         0.07267618,  0.0439366 , -0.09713402, -0.02704799,  0.03429802,\n",
      "         0.02439992,  0.09808095,  0.0444203 , -0.15218274,  0.07256983,\n",
      "        -0.09048308,  0.0884735 ,  0.08630021,  0.14216457, -0.02707961,\n",
      "         0.04301268,  0.07191274,  0.0413883 ,  0.11520441, -0.01182516,\n",
      "         0.07463381, -0.08140307, -0.0022926 , -0.05041067,  0.11556201,\n",
      "         0.00661021, -0.04601833, -0.02904937,  0.01761015, -0.11605066,\n",
      "        -0.13030128, -0.00179632, -0.04505278,  0.14606814,  0.13512199,\n",
      "        -0.13589293,  0.15001006, -0.02634349, -0.01175533, -0.10873646,\n",
      "        -0.05093693, -0.13824181,  0.00821616, -0.10794744, -0.12158909,\n",
      "         0.0809052 , -0.00633904,  0.05314341,  0.026786  , -0.09211324,\n",
      "         0.07297325, -0.05341826,  0.03069492, -0.07380624,  0.1486864 ,\n",
      "        -0.00933766, -0.11601697, -0.1272824 ,  0.13089846,  0.14643084,\n",
      "         0.01551147]], dtype=float32)>, <tf.Variable 'W_e:0' shape=(1, 256) dtype=float32, numpy=\n",
      "array([[-0.0161889 ,  0.12352611,  0.03311239, -0.14165063,  0.01689482,\n",
      "        -0.0308587 ,  0.11550052, -0.11743341,  0.07316302, -0.04303067,\n",
      "        -0.01880629, -0.0756296 , -0.01916508, -0.07567229, -0.13074523,\n",
      "        -0.12188406, -0.07454215,  0.11084391,  0.07856907, -0.04183867,\n",
      "         0.12588318, -0.01355103, -0.02962794,  0.0343743 ,  0.01165387,\n",
      "        -0.10553488, -0.07443428, -0.03111669,  0.00563891, -0.02740809,\n",
      "         0.12244879,  0.13824393, -0.09180301,  0.02907316,  0.06054817,\n",
      "        -0.03756389,  0.03609033, -0.09551719, -0.13019283, -0.08724675,\n",
      "        -0.12907375, -0.04639228, -0.04483978, -0.03092468,  0.06930572,\n",
      "         0.08188725,  0.14127098,  0.06132208,  0.07527007,  0.1073157 ,\n",
      "        -0.10845318,  0.10314749, -0.01871519,  0.06007293, -0.10605785,\n",
      "        -0.09257261, -0.09022647, -0.11149895, -0.12544888, -0.11238308,\n",
      "         0.1402715 , -0.14029762,  0.02239585, -0.1434211 , -0.02358927,\n",
      "         0.1269892 , -0.1313597 ,  0.0513273 ,  0.15136047,  0.09215987,\n",
      "         0.08403574, -0.07900316,  0.06813382,  0.08790542,  0.04221381,\n",
      "        -0.02077208, -0.12730141, -0.1107289 ,  0.06262188,  0.07614507,\n",
      "        -0.09748618,  0.00893094, -0.1169019 , -0.15143937,  0.01792854,\n",
      "        -0.03285324, -0.05723371,  0.1513478 ,  0.10857688, -0.02021243,\n",
      "         0.13134308,  0.09140645, -0.05820247,  0.08788502, -0.01614377,\n",
      "        -0.10983378,  0.15074764, -0.10395542,  0.06624858, -0.04886214,\n",
      "         0.10852368,  0.12971245,  0.01976667, -0.11758772, -0.03877535,\n",
      "        -0.09670722,  0.02376074,  0.0320017 ,  0.12912177, -0.04799756,\n",
      "         0.12033196, -0.08902828, -0.04266959, -0.03682074,  0.04994696,\n",
      "         0.10758059, -0.04821429, -0.03244771,  0.11728252, -0.03627667,\n",
      "         0.03301473, -0.13306752,  0.11975096, -0.1469042 , -0.14873895,\n",
      "         0.0552889 , -0.04358749,  0.06304416, -0.13953935, -0.07098626,\n",
      "         0.09085844, -0.05233617, -0.15195863, -0.01909365,  0.1411239 ,\n",
      "         0.0497223 ,  0.08140303, -0.05794874, -0.10209844, -0.10086255,\n",
      "        -0.03979955, -0.05292927,  0.04650791,  0.13327055,  0.11019175,\n",
      "         0.13266574,  0.14309843,  0.02003965, -0.0413883 ,  0.00877957,\n",
      "        -0.07861325,  0.14565186, -0.13323292,  0.0335298 , -0.05137356,\n",
      "        -0.09132783, -0.01676805, -0.12168782,  0.09657162,  0.06596494,\n",
      "        -0.04588497,  0.0006119 ,  0.04896031,  0.04084791,  0.00990804,\n",
      "        -0.11895502,  0.05545615,  0.02204125,  0.00478013,  0.10186975,\n",
      "         0.0190134 , -0.14361937, -0.12174927, -0.00575995, -0.0814281 ,\n",
      "        -0.0204083 , -0.13961053, -0.10843952, -0.10246597,  0.00075838,\n",
      "         0.09288478,  0.09576847, -0.09610078,  0.04767047,  0.14407818,\n",
      "        -0.06794235,  0.0902523 ,  0.10067172, -0.05784979, -0.04888134,\n",
      "        -0.10712045, -0.1525783 ,  0.10999884,  0.11597212,  0.08149673,\n",
      "        -0.09159522,  0.14573847,  0.05874279, -0.02548981, -0.12884255,\n",
      "         0.04492378,  0.04834801, -0.08821325,  0.07725106,  0.1325943 ,\n",
      "         0.1079639 , -0.11957423,  0.07720512,  0.08487484, -0.03193133,\n",
      "        -0.06153125, -0.10506064, -0.03596942,  0.1418633 ,  0.06208247,\n",
      "         0.11079459,  0.09643064, -0.14303334,  0.06369624, -0.10638601,\n",
      "        -0.03194375, -0.0162061 ,  0.12580733,  0.06116168,  0.02576652,\n",
      "         0.10243778,  0.10642378, -0.09362994,  0.0005008 , -0.14019026,\n",
      "         0.03982611,  0.11047541,  0.13085912,  0.00998734,  0.02492104,\n",
      "         0.06404524,  0.06660967,  0.07021892,  0.07820882, -0.00152376,\n",
      "        -0.02334544, -0.10464772, -0.00189042,  0.03768957, -0.11850825,\n",
      "        -0.0288743 , -0.01909135, -0.02643442,  0.0226793 , -0.1335646 ,\n",
      "        -0.09167839, -0.01766752, -0.07415159, -0.01806803, -0.04185183,\n",
      "         0.06988429]], dtype=float32)>, <tf.Variable 'b:0' shape=(1, 1, 1) dtype=float32, numpy=array([[[-0.29086268]]], dtype=float32)>, <tf.Variable 'U:0' shape=(1, 256, 256) dtype=float32, numpy=\n",
      "array([[[-0.03914206,  0.0131602 , -0.07512956, ..., -0.04608422,\n",
      "         -0.0721419 ,  0.08307635],\n",
      "        [-0.02362907, -0.08197754, -0.0376233 , ..., -0.00472619,\n",
      "          0.03987864,  0.0018211 ],\n",
      "        [-0.03017776, -0.0864269 ,  0.09487844, ...,  0.05842989,\n",
      "         -0.03028869, -0.05711557],\n",
      "        ...,\n",
      "        [-0.08676831, -0.03645188, -0.05803916, ..., -0.01980858,\n",
      "          0.06024594, -0.05844053],\n",
      "        [-0.02874133, -0.0470752 , -0.01594967, ...,  0.07593361,\n",
      "          0.09749711, -0.06773114],\n",
      "        [ 0.10198978,  0.03044721,  0.09355036, ...,  0.10478509,\n",
      "          0.04508645,  0.01276278]]], dtype=float32)>, <tf.Variable 'U:0' shape=(35, 128, 128) dtype=float32, numpy=\n",
      "array([[[ 9.81516205e-03,  1.97458509e-02, -3.36758979e-03, ...,\n",
      "         -2.10267678e-02,  1.06177684e-02,  9.71941464e-03],\n",
      "        [ 2.35196520e-02, -2.24518124e-02, -8.20368528e-04, ...,\n",
      "          1.21512823e-03, -1.37540260e-02, -1.20888269e-02],\n",
      "        [ 2.18538176e-02,  1.57283004e-02, -4.01526876e-03, ...,\n",
      "          1.00595132e-03,  9.80162062e-03,  1.51982401e-02],\n",
      "        ...,\n",
      "        [-2.36714520e-02,  2.29540598e-02, -2.23066658e-02, ...,\n",
      "         -9.26448964e-03,  2.14780960e-02,  1.00521352e-02],\n",
      "        [-1.32161174e-02, -4.22900543e-04,  8.45294259e-03, ...,\n",
      "         -1.45499567e-02,  1.35368649e-02,  5.86981513e-03],\n",
      "        [-1.48220388e-02, -2.37373132e-02, -2.46640481e-03, ...,\n",
      "         -1.35149332e-02,  8.53036158e-03,  1.87440645e-02]],\n",
      "\n",
      "       [[-4.40029241e-03, -2.53957808e-02,  2.85235420e-03, ...,\n",
      "          9.86690260e-03,  2.34878119e-02, -1.27594024e-02],\n",
      "        [-2.57300287e-02,  4.54271957e-03, -6.97586313e-03, ...,\n",
      "          2.28699315e-02,  2.22050678e-02,  5.30805998e-03],\n",
      "        [-2.21737847e-03, -1.93353910e-02, -1.67091191e-03, ...,\n",
      "         -1.67891644e-02, -2.40471400e-02,  3.77590954e-03],\n",
      "        ...,\n",
      "        [-8.10211152e-03, -1.94700994e-02,  2.49652062e-02, ...,\n",
      "         -1.92768164e-02,  1.09737385e-02,  1.37629863e-02],\n",
      "        [ 9.20722820e-03, -1.42599456e-02,  5.95221110e-03, ...,\n",
      "         -6.15077466e-03, -1.45615805e-02,  1.04619097e-02],\n",
      "        [-5.72872721e-03,  1.92256775e-02,  8.57613981e-04, ...,\n",
      "         -1.19192721e-02, -1.59765072e-02, -2.93660723e-03]],\n",
      "\n",
      "       [[-5.63700311e-03,  1.26025695e-02,  2.40407418e-02, ...,\n",
      "         -6.70593977e-03,  2.48517897e-02, -8.70233402e-03],\n",
      "        [ 1.69584285e-02, -1.09076565e-02, -1.69914663e-02, ...,\n",
      "         -1.50744952e-02,  9.95678268e-03,  1.40236411e-02],\n",
      "        [ 5.72103821e-03, -2.41394583e-02, -4.43280116e-03, ...,\n",
      "          2.26859506e-02,  1.57910828e-02, -3.14446352e-03],\n",
      "        ...,\n",
      "        [ 2.18854006e-02,  8.85375030e-03, -8.34316015e-05, ...,\n",
      "          2.58515645e-02, -2.11681705e-02,  2.05328073e-02],\n",
      "        [ 7.04043545e-03,  2.38138903e-02,  1.70040820e-02, ...,\n",
      "          1.44961271e-02, -9.25124995e-03,  2.42339876e-02],\n",
      "        [-1.47963976e-02, -1.13191800e-02, -4.66136262e-03, ...,\n",
      "          7.46729039e-03,  1.04225371e-02,  4.21369821e-03]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-7.78267160e-04,  2.51581240e-02,  2.28908230e-02, ...,\n",
      "          1.62384640e-02,  3.12167220e-03, -1.01707876e-04],\n",
      "        [-1.26594901e-02,  2.46458519e-02, -8.88876803e-03, ...,\n",
      "          3.27742659e-03,  9.52905603e-03,  1.23806670e-03],\n",
      "        [ 1.56758148e-02, -2.18980182e-02,  2.17683632e-02, ...,\n",
      "          1.79125611e-02,  8.54738988e-03, -1.11128967e-02],\n",
      "        ...,\n",
      "        [ 1.50723737e-02, -4.88099642e-03,  3.11171450e-03, ...,\n",
      "         -2.15184782e-02, -1.54617159e-02, -4.69688140e-03],\n",
      "        [ 1.38920415e-02,  2.10056920e-02,  7.18735158e-04, ...,\n",
      "          6.88772835e-03,  3.99865396e-03, -3.78286466e-04],\n",
      "        [ 7.67223351e-03,  3.04576755e-03, -1.42105818e-02, ...,\n",
      "         -1.40473628e-02, -1.59025081e-02,  1.45136621e-02]],\n",
      "\n",
      "       [[-2.01216340e-03, -1.15074841e-02,  8.89039598e-03, ...,\n",
      "          1.38998199e-02,  7.35832192e-03, -1.48109272e-02],\n",
      "        [ 1.41134355e-02, -3.54062393e-03,  1.40509196e-03, ...,\n",
      "          1.22076478e-02, -1.51708042e-02,  1.65767241e-02],\n",
      "        [-2.30311453e-02, -6.25615939e-04, -2.13825721e-02, ...,\n",
      "          1.02912877e-02,  9.13799740e-03, -1.32769756e-02],\n",
      "        ...,\n",
      "        [-5.68963587e-05, -5.54244034e-03, -8.80800188e-04, ...,\n",
      "         -1.60655230e-02,  1.35704037e-02,  1.02960337e-02],\n",
      "        [-9.66213085e-03, -6.96885400e-03, -1.61998980e-02, ...,\n",
      "         -1.62378047e-02,  3.29212844e-03,  7.04385899e-03],\n",
      "        [ 2.29916349e-03, -5.35837375e-03, -2.36498080e-02, ...,\n",
      "         -1.48854200e-02, -1.69389881e-02, -1.52531629e-02]],\n",
      "\n",
      "       [[ 1.24968756e-02, -1.23001505e-02, -1.13035459e-02, ...,\n",
      "          8.97444226e-03, -2.31943503e-02, -1.22905876e-02],\n",
      "        [ 2.41189245e-02,  5.46022318e-03,  5.46157546e-03, ...,\n",
      "          2.37408858e-02, -1.31075624e-02, -1.76833831e-02],\n",
      "        [-1.86140519e-02,  2.61992402e-03,  1.70023497e-02, ...,\n",
      "          4.20061685e-03, -3.08934599e-04, -2.14177519e-02],\n",
      "        ...,\n",
      "        [-1.69594958e-02, -6.09730370e-03, -2.03563347e-02, ...,\n",
      "          2.46949885e-02, -2.48206314e-02,  7.19406642e-03],\n",
      "        [ 1.40714087e-03,  1.30933430e-02, -2.01851688e-02, ...,\n",
      "         -2.03125365e-02,  2.75006704e-03, -5.40162995e-03],\n",
      "        [-2.18855049e-02, -1.65001526e-02,  2.11671088e-02, ...,\n",
      "         -2.24969815e-02, -1.31396698e-02,  8.38544033e-03]]],\n",
      "      dtype=float32)>, <tf.Variable 'W_l:0' shape=(128, 35) dtype=float32, numpy=\n",
      "array([[ 0.01511298,  0.1502979 ,  0.10977562, ...,  0.18575408,\n",
      "        -0.1189166 ,  0.11410864],\n",
      "       [ 0.16676383,  0.10448019,  0.19135733, ...,  0.11292468,\n",
      "        -0.03937455, -0.15829137],\n",
      "       [-0.12533557, -0.00373338, -0.13832001, ...,  0.17458002,\n",
      "        -0.03489199,  0.08557163],\n",
      "       ...,\n",
      "       [ 0.10731323,  0.02535185,  0.10257663, ..., -0.1816165 ,\n",
      "        -0.15560505, -0.05925822],\n",
      "       [ 0.19126736, -0.03618564, -0.04608931, ..., -0.15067786,\n",
      "        -0.03932875,  0.12323202],\n",
      "       [-0.03999528,  0.01924826, -0.19068165, ..., -0.04540628,\n",
      "         0.1688735 ,  0.12449704]], dtype=float32)>, <tf.Variable 'W_r:0' shape=(128, 35) dtype=float32, numpy=\n",
      "array([[ 0.09371154, -0.16008595, -0.03124923, ...,  0.15377112,\n",
      "         0.10095809, -0.0919837 ],\n",
      "       [-0.18445049, -0.04416619, -0.1341674 , ..., -0.17254837,\n",
      "         0.18514375,  0.1797541 ],\n",
      "       [ 0.11838888,  0.11411859, -0.12609409, ..., -0.07340662,\n",
      "         0.03845558, -0.09529794],\n",
      "       ...,\n",
      "       [-0.02695128,  0.11815147,  0.17623575, ..., -0.03216271,\n",
      "        -0.08842482,  0.18123235],\n",
      "       [ 0.17221515,  0.02889617, -0.08959708, ...,  0.11870851,\n",
      "         0.18055443,  0.10990392],\n",
      "       [ 0.0402088 ,  0.14610507,  0.16835825, ..., -0.06504206,\n",
      "        -0.06291182, -0.1390782 ]], dtype=float32)>, <tf.Variable 'bias:0' shape=(35,) dtype=float32, numpy=\n",
      "array([-0.03157821,  0.10679188, -0.18536626, -0.16868055, -0.02762911,\n",
      "       -0.22267693,  0.14963603, -0.28872815,  0.19319075, -0.05814826,\n",
      "       -0.08159727, -0.10709378,  0.11037984,  0.270077  ,  0.2257343 ,\n",
      "       -0.12463176, -0.16953778, -0.2387428 , -0.19984189,  0.27797848,\n",
      "       -0.17273575,  0.20463443, -0.21137497, -0.21898134, -0.19247557,\n",
      "       -0.26223892,  0.06638291,  0.11366144,  0.15715542,  0.16873813,\n",
      "       -0.06022996, -0.27409917, -0.03025156,  0.18625072,  0.22816336],\n",
      "      dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "model = text_to_amr.generate_model()\n",
    "model.compile(optimizer='rmsprop', loss=\"mean_squared_error\")\n",
    "model.run_eagerly = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "token_encoder_input (InputLayer [(40, 25)]           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pos_encoder_input (InputLayer)  [(40, 25)]           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_decoder_input (InputLayer [(40, 28)]           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Encoder)               ((40, 25, 400), ((40 676600      token_encoder_input[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pos_decoder_input (InputLayer)  [(40, 28)]           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Decoder)               ((40, 28, 400), (28, 1152102     token_decoder_input[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "corefs_input (InputLayer)       [(40, 28)]           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_heads_input (InputLayer)   [(40, 28)]           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_labels_input (InputLayer)  [(40, 28)]           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask_input (InputLayer)         [(40, 28)]           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "deep_biaffine_decoder (DeepBiaf ((40, 28), (40, 29)) 956852      decoder[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (40, 28)             0           deep_biaffine_decoder[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "copy_attention_maps_input (Inpu [(40, 25, 27)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "coref_attention_maps_input (Inp [(40, 28, 29)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (40, 1)              29          flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,785,583\n",
      "Trainable params: 2,723,883\n",
      "Non-trainable params: 61,700\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['encoder/embedding/embeddings:0', 'encoder/bidirectional/forward_lstm/kernel:0', 'encoder/bidirectional/forward_lstm/recurrent_kernel:0', 'encoder/bidirectional/forward_lstm/bias:0', 'encoder/bidirectional/backward_lstm/kernel:0', 'encoder/bidirectional/backward_lstm/recurrent_kernel:0', 'encoder/bidirectional/backward_lstm/bias:0', 'decoder/embedding_1/embeddings:0', 'decoder/lstm_1/kernel:0', 'decoder/lstm_1/recurrent_kernel:0', 'decoder/lstm_1/bias:0', 'decoder/bahdanau_attention/dense_1/kernel:0', 'decoder/bahdanau_attention/dense_1/bias:0', 'decoder/bahdanau_attention/dense_2/kernel:0', 'decoder/bahdanau_attention/dense_2/bias:0', 'decoder/bahdanau_attention/dense_3/kernel:0', 'decoder/bahdanau_attention/dense_3/bias:0', 'decoder/bahdanau_attention_1_1/dense_4/kernel:0', 'decoder/bahdanau_attention_1_1/dense_4/bias:0', 'decoder/bahdanau_attention_1_1/dense_5/kernel:0', 'decoder/bahdanau_attention_1_1/dense_5/bias:0', 'decoder/bahdanau_attention_1_1/dense_6/kernel:0', 'decoder/bahdanau_attention_1_1/dense_6/bias:0', 'deep_biaffine_decoder/dense_9/kernel:0', 'deep_biaffine_decoder/dense_9/bias:0', 'deep_biaffine_decoder/dense_10/kernel:0', 'deep_biaffine_decoder/dense_10/bias:0', 'deep_biaffine_decoder/dense_11/kernel:0', 'deep_biaffine_decoder/dense_11/bias:0', 'deep_biaffine_decoder/dense_12/kernel:0', 'deep_biaffine_decoder/dense_12/bias:0', 'sentinel:0', 'W_d:0', 'W_e:0', 'b:0', 'U:0', 'U:0', 'W_l:0', 'W_r:0', 'bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-03-17 17:51:33,540 WARNING] Gradients do not exist for variables ['encoder/embedding/embeddings:0', 'encoder/bidirectional/forward_lstm/kernel:0', 'encoder/bidirectional/forward_lstm/recurrent_kernel:0', 'encoder/bidirectional/forward_lstm/bias:0', 'encoder/bidirectional/backward_lstm/kernel:0', 'encoder/bidirectional/backward_lstm/recurrent_kernel:0', 'encoder/bidirectional/backward_lstm/bias:0', 'decoder/embedding_1/embeddings:0', 'decoder/lstm_1/kernel:0', 'decoder/lstm_1/recurrent_kernel:0', 'decoder/lstm_1/bias:0', 'decoder/bahdanau_attention/dense_1/kernel:0', 'decoder/bahdanau_attention/dense_1/bias:0', 'decoder/bahdanau_attention/dense_2/kernel:0', 'decoder/bahdanau_attention/dense_2/bias:0', 'decoder/bahdanau_attention/dense_3/kernel:0', 'decoder/bahdanau_attention/dense_3/bias:0', 'decoder/bahdanau_attention_1_1/dense_4/kernel:0', 'decoder/bahdanau_attention_1_1/dense_4/bias:0', 'decoder/bahdanau_attention_1_1/dense_5/kernel:0', 'decoder/bahdanau_attention_1_1/dense_5/bias:0', 'decoder/bahdanau_attention_1_1/dense_6/kernel:0', 'decoder/bahdanau_attention_1_1/dense_6/bias:0', 'deep_biaffine_decoder/dense_9/kernel:0', 'deep_biaffine_decoder/dense_9/bias:0', 'deep_biaffine_decoder/dense_10/kernel:0', 'deep_biaffine_decoder/dense_10/bias:0', 'deep_biaffine_decoder/dense_11/kernel:0', 'deep_biaffine_decoder/dense_11/bias:0', 'deep_biaffine_decoder/dense_12/kernel:0', 'deep_biaffine_decoder/dense_12/bias:0', 'sentinel:0', 'W_d:0', 'W_e:0', 'b:0', 'U:0', 'U:0', 'W_l:0', 'W_r:0', 'bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 60ms/sample - loss: 11.5389\n",
      "Epoch 2/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['encoder/embedding/embeddings:0', 'encoder/bidirectional/forward_lstm/kernel:0', 'encoder/bidirectional/forward_lstm/recurrent_kernel:0', 'encoder/bidirectional/forward_lstm/bias:0', 'encoder/bidirectional/backward_lstm/kernel:0', 'encoder/bidirectional/backward_lstm/recurrent_kernel:0', 'encoder/bidirectional/backward_lstm/bias:0', 'decoder/embedding_1/embeddings:0', 'decoder/lstm_1/kernel:0', 'decoder/lstm_1/recurrent_kernel:0', 'decoder/lstm_1/bias:0', 'decoder/bahdanau_attention/dense_1/kernel:0', 'decoder/bahdanau_attention/dense_1/bias:0', 'decoder/bahdanau_attention/dense_2/kernel:0', 'decoder/bahdanau_attention/dense_2/bias:0', 'decoder/bahdanau_attention/dense_3/kernel:0', 'decoder/bahdanau_attention/dense_3/bias:0', 'decoder/bahdanau_attention_1_1/dense_4/kernel:0', 'decoder/bahdanau_attention_1_1/dense_4/bias:0', 'decoder/bahdanau_attention_1_1/dense_5/kernel:0', 'decoder/bahdanau_attention_1_1/dense_5/bias:0', 'decoder/bahdanau_attention_1_1/dense_6/kernel:0', 'decoder/bahdanau_attention_1_1/dense_6/bias:0', 'deep_biaffine_decoder/dense_9/kernel:0', 'deep_biaffine_decoder/dense_9/bias:0', 'deep_biaffine_decoder/dense_10/kernel:0', 'deep_biaffine_decoder/dense_10/bias:0', 'deep_biaffine_decoder/dense_11/kernel:0', 'deep_biaffine_decoder/dense_11/bias:0', 'deep_biaffine_decoder/dense_12/kernel:0', 'deep_biaffine_decoder/dense_12/bias:0', 'sentinel:0', 'W_d:0', 'W_e:0', 'b:0', 'U:0', 'U:0', 'W_l:0', 'W_r:0', 'bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-03-17 17:51:35,704 WARNING] Gradients do not exist for variables ['encoder/embedding/embeddings:0', 'encoder/bidirectional/forward_lstm/kernel:0', 'encoder/bidirectional/forward_lstm/recurrent_kernel:0', 'encoder/bidirectional/forward_lstm/bias:0', 'encoder/bidirectional/backward_lstm/kernel:0', 'encoder/bidirectional/backward_lstm/recurrent_kernel:0', 'encoder/bidirectional/backward_lstm/bias:0', 'decoder/embedding_1/embeddings:0', 'decoder/lstm_1/kernel:0', 'decoder/lstm_1/recurrent_kernel:0', 'decoder/lstm_1/bias:0', 'decoder/bahdanau_attention/dense_1/kernel:0', 'decoder/bahdanau_attention/dense_1/bias:0', 'decoder/bahdanau_attention/dense_2/kernel:0', 'decoder/bahdanau_attention/dense_2/bias:0', 'decoder/bahdanau_attention/dense_3/kernel:0', 'decoder/bahdanau_attention/dense_3/bias:0', 'decoder/bahdanau_attention_1_1/dense_4/kernel:0', 'decoder/bahdanau_attention_1_1/dense_4/bias:0', 'decoder/bahdanau_attention_1_1/dense_5/kernel:0', 'decoder/bahdanau_attention_1_1/dense_5/bias:0', 'decoder/bahdanau_attention_1_1/dense_6/kernel:0', 'decoder/bahdanau_attention_1_1/dense_6/bias:0', 'deep_biaffine_decoder/dense_9/kernel:0', 'deep_biaffine_decoder/dense_9/bias:0', 'deep_biaffine_decoder/dense_10/kernel:0', 'deep_biaffine_decoder/dense_10/bias:0', 'deep_biaffine_decoder/dense_11/kernel:0', 'deep_biaffine_decoder/dense_11/bias:0', 'deep_biaffine_decoder/dense_12/kernel:0', 'deep_biaffine_decoder/dense_12/bias:0', 'sentinel:0', 'W_d:0', 'W_e:0', 'b:0', 'U:0', 'U:0', 'W_l:0', 'W_r:0', 'bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 53ms/sample - loss: 10.5546\n",
      "Epoch 3/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['encoder/embedding/embeddings:0', 'encoder/bidirectional/forward_lstm/kernel:0', 'encoder/bidirectional/forward_lstm/recurrent_kernel:0', 'encoder/bidirectional/forward_lstm/bias:0', 'encoder/bidirectional/backward_lstm/kernel:0', 'encoder/bidirectional/backward_lstm/recurrent_kernel:0', 'encoder/bidirectional/backward_lstm/bias:0', 'decoder/embedding_1/embeddings:0', 'decoder/lstm_1/kernel:0', 'decoder/lstm_1/recurrent_kernel:0', 'decoder/lstm_1/bias:0', 'decoder/bahdanau_attention/dense_1/kernel:0', 'decoder/bahdanau_attention/dense_1/bias:0', 'decoder/bahdanau_attention/dense_2/kernel:0', 'decoder/bahdanau_attention/dense_2/bias:0', 'decoder/bahdanau_attention/dense_3/kernel:0', 'decoder/bahdanau_attention/dense_3/bias:0', 'decoder/bahdanau_attention_1_1/dense_4/kernel:0', 'decoder/bahdanau_attention_1_1/dense_4/bias:0', 'decoder/bahdanau_attention_1_1/dense_5/kernel:0', 'decoder/bahdanau_attention_1_1/dense_5/bias:0', 'decoder/bahdanau_attention_1_1/dense_6/kernel:0', 'decoder/bahdanau_attention_1_1/dense_6/bias:0', 'deep_biaffine_decoder/dense_9/kernel:0', 'deep_biaffine_decoder/dense_9/bias:0', 'deep_biaffine_decoder/dense_10/kernel:0', 'deep_biaffine_decoder/dense_10/bias:0', 'deep_biaffine_decoder/dense_11/kernel:0', 'deep_biaffine_decoder/dense_11/bias:0', 'deep_biaffine_decoder/dense_12/kernel:0', 'deep_biaffine_decoder/dense_12/bias:0', 'sentinel:0', 'W_d:0', 'W_e:0', 'b:0', 'U:0', 'U:0', 'W_l:0', 'W_r:0', 'bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-03-17 17:51:37,682 WARNING] Gradients do not exist for variables ['encoder/embedding/embeddings:0', 'encoder/bidirectional/forward_lstm/kernel:0', 'encoder/bidirectional/forward_lstm/recurrent_kernel:0', 'encoder/bidirectional/forward_lstm/bias:0', 'encoder/bidirectional/backward_lstm/kernel:0', 'encoder/bidirectional/backward_lstm/recurrent_kernel:0', 'encoder/bidirectional/backward_lstm/bias:0', 'decoder/embedding_1/embeddings:0', 'decoder/lstm_1/kernel:0', 'decoder/lstm_1/recurrent_kernel:0', 'decoder/lstm_1/bias:0', 'decoder/bahdanau_attention/dense_1/kernel:0', 'decoder/bahdanau_attention/dense_1/bias:0', 'decoder/bahdanau_attention/dense_2/kernel:0', 'decoder/bahdanau_attention/dense_2/bias:0', 'decoder/bahdanau_attention/dense_3/kernel:0', 'decoder/bahdanau_attention/dense_3/bias:0', 'decoder/bahdanau_attention_1_1/dense_4/kernel:0', 'decoder/bahdanau_attention_1_1/dense_4/bias:0', 'decoder/bahdanau_attention_1_1/dense_5/kernel:0', 'decoder/bahdanau_attention_1_1/dense_5/bias:0', 'decoder/bahdanau_attention_1_1/dense_6/kernel:0', 'decoder/bahdanau_attention_1_1/dense_6/bias:0', 'deep_biaffine_decoder/dense_9/kernel:0', 'deep_biaffine_decoder/dense_9/bias:0', 'deep_biaffine_decoder/dense_10/kernel:0', 'deep_biaffine_decoder/dense_10/bias:0', 'deep_biaffine_decoder/dense_11/kernel:0', 'deep_biaffine_decoder/dense_11/bias:0', 'deep_biaffine_decoder/dense_12/kernel:0', 'deep_biaffine_decoder/dense_12/bias:0', 'sentinel:0', 'W_d:0', 'W_e:0', 'b:0', 'U:0', 'U:0', 'W_l:0', 'W_r:0', 'bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 49ms/sample - loss: 10.9733\n",
      "Epoch 4/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['encoder/embedding/embeddings:0', 'encoder/bidirectional/forward_lstm/kernel:0', 'encoder/bidirectional/forward_lstm/recurrent_kernel:0', 'encoder/bidirectional/forward_lstm/bias:0', 'encoder/bidirectional/backward_lstm/kernel:0', 'encoder/bidirectional/backward_lstm/recurrent_kernel:0', 'encoder/bidirectional/backward_lstm/bias:0', 'decoder/embedding_1/embeddings:0', 'decoder/lstm_1/kernel:0', 'decoder/lstm_1/recurrent_kernel:0', 'decoder/lstm_1/bias:0', 'decoder/bahdanau_attention/dense_1/kernel:0', 'decoder/bahdanau_attention/dense_1/bias:0', 'decoder/bahdanau_attention/dense_2/kernel:0', 'decoder/bahdanau_attention/dense_2/bias:0', 'decoder/bahdanau_attention/dense_3/kernel:0', 'decoder/bahdanau_attention/dense_3/bias:0', 'decoder/bahdanau_attention_1_1/dense_4/kernel:0', 'decoder/bahdanau_attention_1_1/dense_4/bias:0', 'decoder/bahdanau_attention_1_1/dense_5/kernel:0', 'decoder/bahdanau_attention_1_1/dense_5/bias:0', 'decoder/bahdanau_attention_1_1/dense_6/kernel:0', 'decoder/bahdanau_attention_1_1/dense_6/bias:0', 'deep_biaffine_decoder/dense_9/kernel:0', 'deep_biaffine_decoder/dense_9/bias:0', 'deep_biaffine_decoder/dense_10/kernel:0', 'deep_biaffine_decoder/dense_10/bias:0', 'deep_biaffine_decoder/dense_11/kernel:0', 'deep_biaffine_decoder/dense_11/bias:0', 'deep_biaffine_decoder/dense_12/kernel:0', 'deep_biaffine_decoder/dense_12/bias:0', 'sentinel:0', 'W_d:0', 'W_e:0', 'b:0', 'U:0', 'U:0', 'W_l:0', 'W_r:0', 'bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-03-17 17:51:39,378 WARNING] Gradients do not exist for variables ['encoder/embedding/embeddings:0', 'encoder/bidirectional/forward_lstm/kernel:0', 'encoder/bidirectional/forward_lstm/recurrent_kernel:0', 'encoder/bidirectional/forward_lstm/bias:0', 'encoder/bidirectional/backward_lstm/kernel:0', 'encoder/bidirectional/backward_lstm/recurrent_kernel:0', 'encoder/bidirectional/backward_lstm/bias:0', 'decoder/embedding_1/embeddings:0', 'decoder/lstm_1/kernel:0', 'decoder/lstm_1/recurrent_kernel:0', 'decoder/lstm_1/bias:0', 'decoder/bahdanau_attention/dense_1/kernel:0', 'decoder/bahdanau_attention/dense_1/bias:0', 'decoder/bahdanau_attention/dense_2/kernel:0', 'decoder/bahdanau_attention/dense_2/bias:0', 'decoder/bahdanau_attention/dense_3/kernel:0', 'decoder/bahdanau_attention/dense_3/bias:0', 'decoder/bahdanau_attention_1_1/dense_4/kernel:0', 'decoder/bahdanau_attention_1_1/dense_4/bias:0', 'decoder/bahdanau_attention_1_1/dense_5/kernel:0', 'decoder/bahdanau_attention_1_1/dense_5/bias:0', 'decoder/bahdanau_attention_1_1/dense_6/kernel:0', 'decoder/bahdanau_attention_1_1/dense_6/bias:0', 'deep_biaffine_decoder/dense_9/kernel:0', 'deep_biaffine_decoder/dense_9/bias:0', 'deep_biaffine_decoder/dense_10/kernel:0', 'deep_biaffine_decoder/dense_10/bias:0', 'deep_biaffine_decoder/dense_11/kernel:0', 'deep_biaffine_decoder/dense_11/bias:0', 'deep_biaffine_decoder/dense_12/kernel:0', 'deep_biaffine_decoder/dense_12/bias:0', 'sentinel:0', 'W_d:0', 'W_e:0', 'b:0', 'U:0', 'U:0', 'W_l:0', 'W_r:0', 'bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 42ms/sample - loss: 18.4316\n",
      "Epoch 5/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['encoder/embedding/embeddings:0', 'encoder/bidirectional/forward_lstm/kernel:0', 'encoder/bidirectional/forward_lstm/recurrent_kernel:0', 'encoder/bidirectional/forward_lstm/bias:0', 'encoder/bidirectional/backward_lstm/kernel:0', 'encoder/bidirectional/backward_lstm/recurrent_kernel:0', 'encoder/bidirectional/backward_lstm/bias:0', 'decoder/embedding_1/embeddings:0', 'decoder/lstm_1/kernel:0', 'decoder/lstm_1/recurrent_kernel:0', 'decoder/lstm_1/bias:0', 'decoder/bahdanau_attention/dense_1/kernel:0', 'decoder/bahdanau_attention/dense_1/bias:0', 'decoder/bahdanau_attention/dense_2/kernel:0', 'decoder/bahdanau_attention/dense_2/bias:0', 'decoder/bahdanau_attention/dense_3/kernel:0', 'decoder/bahdanau_attention/dense_3/bias:0', 'decoder/bahdanau_attention_1_1/dense_4/kernel:0', 'decoder/bahdanau_attention_1_1/dense_4/bias:0', 'decoder/bahdanau_attention_1_1/dense_5/kernel:0', 'decoder/bahdanau_attention_1_1/dense_5/bias:0', 'decoder/bahdanau_attention_1_1/dense_6/kernel:0', 'decoder/bahdanau_attention_1_1/dense_6/bias:0', 'deep_biaffine_decoder/dense_9/kernel:0', 'deep_biaffine_decoder/dense_9/bias:0', 'deep_biaffine_decoder/dense_10/kernel:0', 'deep_biaffine_decoder/dense_10/bias:0', 'deep_biaffine_decoder/dense_11/kernel:0', 'deep_biaffine_decoder/dense_11/bias:0', 'deep_biaffine_decoder/dense_12/kernel:0', 'deep_biaffine_decoder/dense_12/bias:0', 'sentinel:0', 'W_d:0', 'W_e:0', 'b:0', 'U:0', 'U:0', 'W_l:0', 'W_r:0', 'bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-03-17 17:51:41,098 WARNING] Gradients do not exist for variables ['encoder/embedding/embeddings:0', 'encoder/bidirectional/forward_lstm/kernel:0', 'encoder/bidirectional/forward_lstm/recurrent_kernel:0', 'encoder/bidirectional/forward_lstm/bias:0', 'encoder/bidirectional/backward_lstm/kernel:0', 'encoder/bidirectional/backward_lstm/recurrent_kernel:0', 'encoder/bidirectional/backward_lstm/bias:0', 'decoder/embedding_1/embeddings:0', 'decoder/lstm_1/kernel:0', 'decoder/lstm_1/recurrent_kernel:0', 'decoder/lstm_1/bias:0', 'decoder/bahdanau_attention/dense_1/kernel:0', 'decoder/bahdanau_attention/dense_1/bias:0', 'decoder/bahdanau_attention/dense_2/kernel:0', 'decoder/bahdanau_attention/dense_2/bias:0', 'decoder/bahdanau_attention/dense_3/kernel:0', 'decoder/bahdanau_attention/dense_3/bias:0', 'decoder/bahdanau_attention_1_1/dense_4/kernel:0', 'decoder/bahdanau_attention_1_1/dense_4/bias:0', 'decoder/bahdanau_attention_1_1/dense_5/kernel:0', 'decoder/bahdanau_attention_1_1/dense_5/bias:0', 'decoder/bahdanau_attention_1_1/dense_6/kernel:0', 'decoder/bahdanau_attention_1_1/dense_6/bias:0', 'deep_biaffine_decoder/dense_9/kernel:0', 'deep_biaffine_decoder/dense_9/bias:0', 'deep_biaffine_decoder/dense_10/kernel:0', 'deep_biaffine_decoder/dense_10/bias:0', 'deep_biaffine_decoder/dense_11/kernel:0', 'deep_biaffine_decoder/dense_11/bias:0', 'deep_biaffine_decoder/dense_12/kernel:0', 'deep_biaffine_decoder/dense_12/bias:0', 'sentinel:0', 'W_d:0', 'W_e:0', 'b:0', 'U:0', 'U:0', 'W_l:0', 'W_r:0', 'bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 43ms/sample - loss: 21.8358\n",
      "Epoch 6/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['encoder/embedding/embeddings:0', 'encoder/bidirectional/forward_lstm/kernel:0', 'encoder/bidirectional/forward_lstm/recurrent_kernel:0', 'encoder/bidirectional/forward_lstm/bias:0', 'encoder/bidirectional/backward_lstm/kernel:0', 'encoder/bidirectional/backward_lstm/recurrent_kernel:0', 'encoder/bidirectional/backward_lstm/bias:0', 'decoder/embedding_1/embeddings:0', 'decoder/lstm_1/kernel:0', 'decoder/lstm_1/recurrent_kernel:0', 'decoder/lstm_1/bias:0', 'decoder/bahdanau_attention/dense_1/kernel:0', 'decoder/bahdanau_attention/dense_1/bias:0', 'decoder/bahdanau_attention/dense_2/kernel:0', 'decoder/bahdanau_attention/dense_2/bias:0', 'decoder/bahdanau_attention/dense_3/kernel:0', 'decoder/bahdanau_attention/dense_3/bias:0', 'decoder/bahdanau_attention_1_1/dense_4/kernel:0', 'decoder/bahdanau_attention_1_1/dense_4/bias:0', 'decoder/bahdanau_attention_1_1/dense_5/kernel:0', 'decoder/bahdanau_attention_1_1/dense_5/bias:0', 'decoder/bahdanau_attention_1_1/dense_6/kernel:0', 'decoder/bahdanau_attention_1_1/dense_6/bias:0', 'deep_biaffine_decoder/dense_9/kernel:0', 'deep_biaffine_decoder/dense_9/bias:0', 'deep_biaffine_decoder/dense_10/kernel:0', 'deep_biaffine_decoder/dense_10/bias:0', 'deep_biaffine_decoder/dense_11/kernel:0', 'deep_biaffine_decoder/dense_11/bias:0', 'deep_biaffine_decoder/dense_12/kernel:0', 'deep_biaffine_decoder/dense_12/bias:0', 'sentinel:0', 'W_d:0', 'W_e:0', 'b:0', 'U:0', 'U:0', 'W_l:0', 'W_r:0', 'bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-03-17 17:51:42,936 WARNING] Gradients do not exist for variables ['encoder/embedding/embeddings:0', 'encoder/bidirectional/forward_lstm/kernel:0', 'encoder/bidirectional/forward_lstm/recurrent_kernel:0', 'encoder/bidirectional/forward_lstm/bias:0', 'encoder/bidirectional/backward_lstm/kernel:0', 'encoder/bidirectional/backward_lstm/recurrent_kernel:0', 'encoder/bidirectional/backward_lstm/bias:0', 'decoder/embedding_1/embeddings:0', 'decoder/lstm_1/kernel:0', 'decoder/lstm_1/recurrent_kernel:0', 'decoder/lstm_1/bias:0', 'decoder/bahdanau_attention/dense_1/kernel:0', 'decoder/bahdanau_attention/dense_1/bias:0', 'decoder/bahdanau_attention/dense_2/kernel:0', 'decoder/bahdanau_attention/dense_2/bias:0', 'decoder/bahdanau_attention/dense_3/kernel:0', 'decoder/bahdanau_attention/dense_3/bias:0', 'decoder/bahdanau_attention_1_1/dense_4/kernel:0', 'decoder/bahdanau_attention_1_1/dense_4/bias:0', 'decoder/bahdanau_attention_1_1/dense_5/kernel:0', 'decoder/bahdanau_attention_1_1/dense_5/bias:0', 'decoder/bahdanau_attention_1_1/dense_6/kernel:0', 'decoder/bahdanau_attention_1_1/dense_6/bias:0', 'deep_biaffine_decoder/dense_9/kernel:0', 'deep_biaffine_decoder/dense_9/bias:0', 'deep_biaffine_decoder/dense_10/kernel:0', 'deep_biaffine_decoder/dense_10/bias:0', 'deep_biaffine_decoder/dense_11/kernel:0', 'deep_biaffine_decoder/dense_11/bias:0', 'deep_biaffine_decoder/dense_12/kernel:0', 'deep_biaffine_decoder/dense_12/bias:0', 'sentinel:0', 'W_d:0', 'W_e:0', 'b:0', 'U:0', 'U:0', 'W_l:0', 'W_r:0', 'bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 46ms/sample - loss: 8.3265\n",
      "Epoch 7/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['encoder/embedding/embeddings:0', 'encoder/bidirectional/forward_lstm/kernel:0', 'encoder/bidirectional/forward_lstm/recurrent_kernel:0', 'encoder/bidirectional/forward_lstm/bias:0', 'encoder/bidirectional/backward_lstm/kernel:0', 'encoder/bidirectional/backward_lstm/recurrent_kernel:0', 'encoder/bidirectional/backward_lstm/bias:0', 'decoder/embedding_1/embeddings:0', 'decoder/lstm_1/kernel:0', 'decoder/lstm_1/recurrent_kernel:0', 'decoder/lstm_1/bias:0', 'decoder/bahdanau_attention/dense_1/kernel:0', 'decoder/bahdanau_attention/dense_1/bias:0', 'decoder/bahdanau_attention/dense_2/kernel:0', 'decoder/bahdanau_attention/dense_2/bias:0', 'decoder/bahdanau_attention/dense_3/kernel:0', 'decoder/bahdanau_attention/dense_3/bias:0', 'decoder/bahdanau_attention_1_1/dense_4/kernel:0', 'decoder/bahdanau_attention_1_1/dense_4/bias:0', 'decoder/bahdanau_attention_1_1/dense_5/kernel:0', 'decoder/bahdanau_attention_1_1/dense_5/bias:0', 'decoder/bahdanau_attention_1_1/dense_6/kernel:0', 'decoder/bahdanau_attention_1_1/dense_6/bias:0', 'deep_biaffine_decoder/dense_9/kernel:0', 'deep_biaffine_decoder/dense_9/bias:0', 'deep_biaffine_decoder/dense_10/kernel:0', 'deep_biaffine_decoder/dense_10/bias:0', 'deep_biaffine_decoder/dense_11/kernel:0', 'deep_biaffine_decoder/dense_11/bias:0', 'deep_biaffine_decoder/dense_12/kernel:0', 'deep_biaffine_decoder/dense_12/bias:0', 'sentinel:0', 'W_d:0', 'W_e:0', 'b:0', 'U:0', 'U:0', 'W_l:0', 'W_r:0', 'bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-03-17 17:51:45,265 WARNING] Gradients do not exist for variables ['encoder/embedding/embeddings:0', 'encoder/bidirectional/forward_lstm/kernel:0', 'encoder/bidirectional/forward_lstm/recurrent_kernel:0', 'encoder/bidirectional/forward_lstm/bias:0', 'encoder/bidirectional/backward_lstm/kernel:0', 'encoder/bidirectional/backward_lstm/recurrent_kernel:0', 'encoder/bidirectional/backward_lstm/bias:0', 'decoder/embedding_1/embeddings:0', 'decoder/lstm_1/kernel:0', 'decoder/lstm_1/recurrent_kernel:0', 'decoder/lstm_1/bias:0', 'decoder/bahdanau_attention/dense_1/kernel:0', 'decoder/bahdanau_attention/dense_1/bias:0', 'decoder/bahdanau_attention/dense_2/kernel:0', 'decoder/bahdanau_attention/dense_2/bias:0', 'decoder/bahdanau_attention/dense_3/kernel:0', 'decoder/bahdanau_attention/dense_3/bias:0', 'decoder/bahdanau_attention_1_1/dense_4/kernel:0', 'decoder/bahdanau_attention_1_1/dense_4/bias:0', 'decoder/bahdanau_attention_1_1/dense_5/kernel:0', 'decoder/bahdanau_attention_1_1/dense_5/bias:0', 'decoder/bahdanau_attention_1_1/dense_6/kernel:0', 'decoder/bahdanau_attention_1_1/dense_6/bias:0', 'deep_biaffine_decoder/dense_9/kernel:0', 'deep_biaffine_decoder/dense_9/bias:0', 'deep_biaffine_decoder/dense_10/kernel:0', 'deep_biaffine_decoder/dense_10/bias:0', 'deep_biaffine_decoder/dense_11/kernel:0', 'deep_biaffine_decoder/dense_11/bias:0', 'deep_biaffine_decoder/dense_12/kernel:0', 'deep_biaffine_decoder/dense_12/bias:0', 'sentinel:0', 'W_d:0', 'W_e:0', 'b:0', 'U:0', 'U:0', 'W_l:0', 'W_r:0', 'bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 58ms/sample - loss: 12.4460\n",
      "Epoch 8/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['encoder/embedding/embeddings:0', 'encoder/bidirectional/forward_lstm/kernel:0', 'encoder/bidirectional/forward_lstm/recurrent_kernel:0', 'encoder/bidirectional/forward_lstm/bias:0', 'encoder/bidirectional/backward_lstm/kernel:0', 'encoder/bidirectional/backward_lstm/recurrent_kernel:0', 'encoder/bidirectional/backward_lstm/bias:0', 'decoder/embedding_1/embeddings:0', 'decoder/lstm_1/kernel:0', 'decoder/lstm_1/recurrent_kernel:0', 'decoder/lstm_1/bias:0', 'decoder/bahdanau_attention/dense_1/kernel:0', 'decoder/bahdanau_attention/dense_1/bias:0', 'decoder/bahdanau_attention/dense_2/kernel:0', 'decoder/bahdanau_attention/dense_2/bias:0', 'decoder/bahdanau_attention/dense_3/kernel:0', 'decoder/bahdanau_attention/dense_3/bias:0', 'decoder/bahdanau_attention_1_1/dense_4/kernel:0', 'decoder/bahdanau_attention_1_1/dense_4/bias:0', 'decoder/bahdanau_attention_1_1/dense_5/kernel:0', 'decoder/bahdanau_attention_1_1/dense_5/bias:0', 'decoder/bahdanau_attention_1_1/dense_6/kernel:0', 'decoder/bahdanau_attention_1_1/dense_6/bias:0', 'deep_biaffine_decoder/dense_9/kernel:0', 'deep_biaffine_decoder/dense_9/bias:0', 'deep_biaffine_decoder/dense_10/kernel:0', 'deep_biaffine_decoder/dense_10/bias:0', 'deep_biaffine_decoder/dense_11/kernel:0', 'deep_biaffine_decoder/dense_11/bias:0', 'deep_biaffine_decoder/dense_12/kernel:0', 'deep_biaffine_decoder/dense_12/bias:0', 'sentinel:0', 'W_d:0', 'W_e:0', 'b:0', 'U:0', 'U:0', 'W_l:0', 'W_r:0', 'bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-03-17 17:51:47,271 WARNING] Gradients do not exist for variables ['encoder/embedding/embeddings:0', 'encoder/bidirectional/forward_lstm/kernel:0', 'encoder/bidirectional/forward_lstm/recurrent_kernel:0', 'encoder/bidirectional/forward_lstm/bias:0', 'encoder/bidirectional/backward_lstm/kernel:0', 'encoder/bidirectional/backward_lstm/recurrent_kernel:0', 'encoder/bidirectional/backward_lstm/bias:0', 'decoder/embedding_1/embeddings:0', 'decoder/lstm_1/kernel:0', 'decoder/lstm_1/recurrent_kernel:0', 'decoder/lstm_1/bias:0', 'decoder/bahdanau_attention/dense_1/kernel:0', 'decoder/bahdanau_attention/dense_1/bias:0', 'decoder/bahdanau_attention/dense_2/kernel:0', 'decoder/bahdanau_attention/dense_2/bias:0', 'decoder/bahdanau_attention/dense_3/kernel:0', 'decoder/bahdanau_attention/dense_3/bias:0', 'decoder/bahdanau_attention_1_1/dense_4/kernel:0', 'decoder/bahdanau_attention_1_1/dense_4/bias:0', 'decoder/bahdanau_attention_1_1/dense_5/kernel:0', 'decoder/bahdanau_attention_1_1/dense_5/bias:0', 'decoder/bahdanau_attention_1_1/dense_6/kernel:0', 'decoder/bahdanau_attention_1_1/dense_6/bias:0', 'deep_biaffine_decoder/dense_9/kernel:0', 'deep_biaffine_decoder/dense_9/bias:0', 'deep_biaffine_decoder/dense_10/kernel:0', 'deep_biaffine_decoder/dense_10/bias:0', 'deep_biaffine_decoder/dense_11/kernel:0', 'deep_biaffine_decoder/dense_11/bias:0', 'deep_biaffine_decoder/dense_12/kernel:0', 'deep_biaffine_decoder/dense_12/bias:0', 'sentinel:0', 'W_d:0', 'W_e:0', 'b:0', 'U:0', 'U:0', 'W_l:0', 'W_r:0', 'bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 50ms/sample - loss: 8.5764\n",
      "Epoch 9/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['encoder/embedding/embeddings:0', 'encoder/bidirectional/forward_lstm/kernel:0', 'encoder/bidirectional/forward_lstm/recurrent_kernel:0', 'encoder/bidirectional/forward_lstm/bias:0', 'encoder/bidirectional/backward_lstm/kernel:0', 'encoder/bidirectional/backward_lstm/recurrent_kernel:0', 'encoder/bidirectional/backward_lstm/bias:0', 'decoder/embedding_1/embeddings:0', 'decoder/lstm_1/kernel:0', 'decoder/lstm_1/recurrent_kernel:0', 'decoder/lstm_1/bias:0', 'decoder/bahdanau_attention/dense_1/kernel:0', 'decoder/bahdanau_attention/dense_1/bias:0', 'decoder/bahdanau_attention/dense_2/kernel:0', 'decoder/bahdanau_attention/dense_2/bias:0', 'decoder/bahdanau_attention/dense_3/kernel:0', 'decoder/bahdanau_attention/dense_3/bias:0', 'decoder/bahdanau_attention_1_1/dense_4/kernel:0', 'decoder/bahdanau_attention_1_1/dense_4/bias:0', 'decoder/bahdanau_attention_1_1/dense_5/kernel:0', 'decoder/bahdanau_attention_1_1/dense_5/bias:0', 'decoder/bahdanau_attention_1_1/dense_6/kernel:0', 'decoder/bahdanau_attention_1_1/dense_6/bias:0', 'deep_biaffine_decoder/dense_9/kernel:0', 'deep_biaffine_decoder/dense_9/bias:0', 'deep_biaffine_decoder/dense_10/kernel:0', 'deep_biaffine_decoder/dense_10/bias:0', 'deep_biaffine_decoder/dense_11/kernel:0', 'deep_biaffine_decoder/dense_11/bias:0', 'deep_biaffine_decoder/dense_12/kernel:0', 'deep_biaffine_decoder/dense_12/bias:0', 'sentinel:0', 'W_d:0', 'W_e:0', 'b:0', 'U:0', 'U:0', 'W_l:0', 'W_r:0', 'bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-03-17 17:51:49,321 WARNING] Gradients do not exist for variables ['encoder/embedding/embeddings:0', 'encoder/bidirectional/forward_lstm/kernel:0', 'encoder/bidirectional/forward_lstm/recurrent_kernel:0', 'encoder/bidirectional/forward_lstm/bias:0', 'encoder/bidirectional/backward_lstm/kernel:0', 'encoder/bidirectional/backward_lstm/recurrent_kernel:0', 'encoder/bidirectional/backward_lstm/bias:0', 'decoder/embedding_1/embeddings:0', 'decoder/lstm_1/kernel:0', 'decoder/lstm_1/recurrent_kernel:0', 'decoder/lstm_1/bias:0', 'decoder/bahdanau_attention/dense_1/kernel:0', 'decoder/bahdanau_attention/dense_1/bias:0', 'decoder/bahdanau_attention/dense_2/kernel:0', 'decoder/bahdanau_attention/dense_2/bias:0', 'decoder/bahdanau_attention/dense_3/kernel:0', 'decoder/bahdanau_attention/dense_3/bias:0', 'decoder/bahdanau_attention_1_1/dense_4/kernel:0', 'decoder/bahdanau_attention_1_1/dense_4/bias:0', 'decoder/bahdanau_attention_1_1/dense_5/kernel:0', 'decoder/bahdanau_attention_1_1/dense_5/bias:0', 'decoder/bahdanau_attention_1_1/dense_6/kernel:0', 'decoder/bahdanau_attention_1_1/dense_6/bias:0', 'deep_biaffine_decoder/dense_9/kernel:0', 'deep_biaffine_decoder/dense_9/bias:0', 'deep_biaffine_decoder/dense_10/kernel:0', 'deep_biaffine_decoder/dense_10/bias:0', 'deep_biaffine_decoder/dense_11/kernel:0', 'deep_biaffine_decoder/dense_11/bias:0', 'deep_biaffine_decoder/dense_12/kernel:0', 'deep_biaffine_decoder/dense_12/bias:0', 'sentinel:0', 'W_d:0', 'W_e:0', 'b:0', 'U:0', 'U:0', 'W_l:0', 'W_r:0', 'bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 51ms/sample - loss: 16.4884\n",
      "Epoch 10/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['encoder/embedding/embeddings:0', 'encoder/bidirectional/forward_lstm/kernel:0', 'encoder/bidirectional/forward_lstm/recurrent_kernel:0', 'encoder/bidirectional/forward_lstm/bias:0', 'encoder/bidirectional/backward_lstm/kernel:0', 'encoder/bidirectional/backward_lstm/recurrent_kernel:0', 'encoder/bidirectional/backward_lstm/bias:0', 'decoder/embedding_1/embeddings:0', 'decoder/lstm_1/kernel:0', 'decoder/lstm_1/recurrent_kernel:0', 'decoder/lstm_1/bias:0', 'decoder/bahdanau_attention/dense_1/kernel:0', 'decoder/bahdanau_attention/dense_1/bias:0', 'decoder/bahdanau_attention/dense_2/kernel:0', 'decoder/bahdanau_attention/dense_2/bias:0', 'decoder/bahdanau_attention/dense_3/kernel:0', 'decoder/bahdanau_attention/dense_3/bias:0', 'decoder/bahdanau_attention_1_1/dense_4/kernel:0', 'decoder/bahdanau_attention_1_1/dense_4/bias:0', 'decoder/bahdanau_attention_1_1/dense_5/kernel:0', 'decoder/bahdanau_attention_1_1/dense_5/bias:0', 'decoder/bahdanau_attention_1_1/dense_6/kernel:0', 'decoder/bahdanau_attention_1_1/dense_6/bias:0', 'deep_biaffine_decoder/dense_9/kernel:0', 'deep_biaffine_decoder/dense_9/bias:0', 'deep_biaffine_decoder/dense_10/kernel:0', 'deep_biaffine_decoder/dense_10/bias:0', 'deep_biaffine_decoder/dense_11/kernel:0', 'deep_biaffine_decoder/dense_11/bias:0', 'deep_biaffine_decoder/dense_12/kernel:0', 'deep_biaffine_decoder/dense_12/bias:0', 'sentinel:0', 'W_d:0', 'W_e:0', 'b:0', 'U:0', 'U:0', 'W_l:0', 'W_r:0', 'bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-03-17 17:51:51,176 WARNING] Gradients do not exist for variables ['encoder/embedding/embeddings:0', 'encoder/bidirectional/forward_lstm/kernel:0', 'encoder/bidirectional/forward_lstm/recurrent_kernel:0', 'encoder/bidirectional/forward_lstm/bias:0', 'encoder/bidirectional/backward_lstm/kernel:0', 'encoder/bidirectional/backward_lstm/recurrent_kernel:0', 'encoder/bidirectional/backward_lstm/bias:0', 'decoder/embedding_1/embeddings:0', 'decoder/lstm_1/kernel:0', 'decoder/lstm_1/recurrent_kernel:0', 'decoder/lstm_1/bias:0', 'decoder/bahdanau_attention/dense_1/kernel:0', 'decoder/bahdanau_attention/dense_1/bias:0', 'decoder/bahdanau_attention/dense_2/kernel:0', 'decoder/bahdanau_attention/dense_2/bias:0', 'decoder/bahdanau_attention/dense_3/kernel:0', 'decoder/bahdanau_attention/dense_3/bias:0', 'decoder/bahdanau_attention_1_1/dense_4/kernel:0', 'decoder/bahdanau_attention_1_1/dense_4/bias:0', 'decoder/bahdanau_attention_1_1/dense_5/kernel:0', 'decoder/bahdanau_attention_1_1/dense_5/bias:0', 'decoder/bahdanau_attention_1_1/dense_6/kernel:0', 'decoder/bahdanau_attention_1_1/dense_6/bias:0', 'deep_biaffine_decoder/dense_9/kernel:0', 'deep_biaffine_decoder/dense_9/bias:0', 'deep_biaffine_decoder/dense_10/kernel:0', 'deep_biaffine_decoder/dense_10/bias:0', 'deep_biaffine_decoder/dense_11/kernel:0', 'deep_biaffine_decoder/dense_11/bias:0', 'deep_biaffine_decoder/dense_12/kernel:0', 'deep_biaffine_decoder/dense_12/bias:0', 'sentinel:0', 'W_d:0', 'W_e:0', 'b:0', 'U:0', 'U:0', 'W_l:0', 'W_r:0', 'bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 46ms/sample - loss: 9.7729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5e13d5f850>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_encoder_input = encoder_input.get('token')\n",
    "pos_encoder_input = encoder_input.get('pos_tag')\n",
    "token_decoder_input = decoder_input.get('token')\n",
    "pos_decoder_input = decoder_input.get('pos_tag')\n",
    "copy_attention_map_input = generator_input.get('copy_attention_maps')\n",
    "coref_attention_map_input = generator_input.get('coref_attention_maps')\n",
    "edge_heads_input = parser_input.get('edge_heads')\n",
    "edge_labels_input = parser_input.get('edge_labels')\n",
    "parser_mask_input = parser_input.get('mask')\n",
    "coref_input = parser_input.get('corefs')\n",
    "\n",
    "\n",
    "# token_encoder_input, \n",
    "# pos_encoder_input, \n",
    "# token_decoder_input, \n",
    "# pos_decoder_input, \n",
    "# copy_attention_maps_input, \n",
    "# coref_attention_maps_input,\n",
    "# mask_input,\n",
    "# edge_heads_input,\n",
    "# edge_labels_input,\n",
    "# corefs_input,\n",
    "\n",
    "model_input = [\n",
    "    token_encoder_input, \n",
    "    pos_encoder_input, \n",
    "    token_decoder_input, \n",
    "    pos_decoder_input, \n",
    "    copy_attention_map_input, \n",
    "    coref_attention_map_input,\n",
    "    parser_mask_input, \n",
    "    edge_heads_input,\n",
    "    edge_labels_input,\n",
    "    coref_input\n",
    "]\n",
    "\n",
    "model.fit(model_input, np.asarray([1 for _ in range(len(model_input[0]))]), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
